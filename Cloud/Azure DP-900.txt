 	ДанныеСтруктура данных: сущности и атрибуты.Данные: структурированные (есть схема), полуструктурированные и неструктурированные. 	Роли:1\ Администраторы баз данных (доступи, бекап, востонавление)2\ Инженеры данных (инфраструктура и ETL)3\ Аналитики данных (иследования и визуализация)4\ Data scientist (исследования и моделирование)5\ Бизнес-пользователи (готовые отчеты) 	Типы рабочих нагрузок данных:1\ OLTP (онлайн-транзакционная обработка) - ориентированные на быстрое выполнение коротких транзакций (CRUD). Для поддержки  live and line of business приложений - интернет-банкинга, онлайн-магазины...Транзакции поддерживающие ACID:А\ Атомарность – полностью или никак.Б\ Согласованность – только из одного допустимого состояния в другое.В\ Изоляция – параллельные транзакции не могут мешать друг другу.Г\ Устойчивость – после завершения останется подтвержденной.2\ Analytical data processing - для чтения, исторические данные.Архитектура: ETL => Data warehouse/Lake => OLAP-модель или куб => визуализации и дашборды.**Реляционные хранилища в Azure**Реляционные данные - таблицы со схемой. Нормализация (таблицу на каждую сущность, атрибуты по столбцам, строка - одинексемпляр сущности, уникальность строк(ПК), ФК связывают сущности, ссылочная целостность- ФК это ПК).Диалекты: T-SQL - Microsoft SQL Server и службы Azure SQL; pgSQL - PostgreSQL; PL/SQL - Oracle.1.1\ Azure SQL Database (PaaS) - для новых.1.2\ Azure SQL Managed Instance (PaaS) - для миграции с минимальными изменениями и интергация с сервисами.1.3\ SQL Server on Azure VM (IaaS) -  контроль над ресурсам, для "lift and shift".1.4\ Azure Database for MySQL(PaaS)1.5\ Azure Database for MariaDB (совместимость с Oracle Database)1.6\ Azure Database for PostgreSQLТипы операторов SQL:Data Definition Language (DDL) - CREATE, ALTER, DROP, RENAME.Data Control Language (DCL) - GRANT. DENY. REVOKEПР: GRANT SELECT, INSERT, UPDATE    ON Product    TO user1;*Data Manipulation Language (DML) - SELECT, INSERT, UPDATE, DELETEview - это виртуальная таблица результата SELECT.Хранимая процедура (с/без параметров) - SQL-запросы для инкапсуляции, выполняются по команде.ПР: CREATE PROCEDURE RenameProduct @ProductID INT, @NewName VARCHAR(20)AS UPDATE Product SET Name = @NewName WHERE ID = @ProductID;EXEC RenameProduct 201, 'Spanner';Индекс - для быстрого поиска, содержит копию данных колонки в отсортированном порядке.ПР: CREATE INDEX idx\_ProductName    ON Product(Name);**Файловые храилища в Azure**Azure Storage — позволяет хранить данные в Blob containers (бинарных файлов), File shares, таблицах типа «ключ-значение».Форматы: Delimited text files (СSV, TSV); JSON; XML; BLOB; Оптимизированные форматы файлов (Avro, ORC, Parquet).1\ Azure Blob Storage - неструктурированные данные в виде больших двоичных объектов (возможен доступ через API). Хранятся в контейнерах.Виды: Block blobs (макс 4000 MiB X 50,000 blocks); Page blobs (по 512 байт, на виртуальных жестких дисках); Append blobs (до 4 МБ только в конец без обновления или удаления).Три уровня доступа к Blob storage:  Hot (быстрый доступ, дороже хранение), Cool, Archive (доступ несколько часов).2\ Azure Data Lake Storage Gen2 - для иерархического хранения данных.3\ Azure File Storage - облачный сервис для хранения файлов. Утилита AzCopy. Для shared файлов.Поддерживает протоколи совместного доступа: SMB (Server Message Block) как в Windows и NFS (Network File System).4\ Azure Table Storage — таблицы «ключ/значение» с разными столбцами и независимыми разделами. Все строки должны иметь ПК (состоящий из ключа раздела и ключа строки, нет ФК), при изменении данных записывает дату и время изменений.**Нереляционные (NoSQL) БД в Azure**Нереляционные базы данных (NoSQL): Key-value databases (значение любой формат); Document databases (значение в JSON); Column family databases; Графовые базы данных.Azure Cosmos DB - универсальная NOSQL для нереляционных моделей даних (документы (JSON), графы, хранилища типа «ключ-значение» и хранилища семейств столбцов). Совместима с популярными API: SQL, MongoDB, Cassandra, Gremlin, Table. Использует индексы и разделы1\ Azure Cosmos DB for NoSQL — для документоориентированной (JSON) модели данных.Применения: динамическая структурой данных; профили юзеров; каталоги товаров, корзин.ПР: Запрос: SELECT * FROM customers c WHERE c.id = "joe@litware.com"Результат: {    "id": "joe@litware.com",    "name": "Joe Jones",    "address": {"street": "1 Main St.", "city": "Seattle"     } }2\ Azure Cosmos DB for MongoDB - данные в Binary JSON (BSON)Применения: Хранение документов, данных для аналитики, событий; SaaS-платформы.ПР: запрос: db.products.find({id: 123})Результат: {    "id": 123,    "name": "Hammer",    "price": 2.99 }3\ Azure Cosmos DB for PostgreSQL - реляционная глобально распределенная БД.Применения: Транзакции, отчёты, финансовые системы.ПР: SELECT ProductName, Price FROM Products WHERE ProductID = 123; Результат: таблица.4\ Azure Cosmos DB for Table - данные типа «ключ-значение» (аналогично Azure Table Storage) по API таблиц.Применения: Бэкапы, архивы, мониторинг; Логи, телеметрия, события IoT.ПР: https://endpoint/Customers(PartitionKey='1',RowKey='124')5\ Azure Cosmos DB for Apache Cassandra - данные на основе семейств (разных) столбцов. Применения: Приложения с высокой скоростью записи и чтения; Логи, телеметрия, события IoT.ПР: SELECT * FROM Employees WHERE ID = 26\ Azure Cosmos DB for Apache Gremlin - данные в графовой структуре (сущности=вершины, узлы соединены ребрами, представляющими отношения).Применения: социальные сети, рекомендации; Поиск путей, выявление сообществ.Пр: вершины (сотрудник и отдел) и ребра (сотрудник «Бен» подчиняется сотруднику «Сью», и оба сотрудника работают в отделе «Оборудование»).Добавим нового сотрудника: g.addV('employee').property('id', '3').property('firstName', 'Alice')    g.V('3').addE('reports to').to(g.V('1'))Получить сотрудников:  g.V().hasLabel('employee').order().by('id')	Архитектура аналитики данных:1\Data ingestion and processing (ETL/ELT) - многоузловые кластеры. Включает как пакетную обработку статических данных, так и обработку потоковых данных в реальном времени.Data processing - преобразование сырых данных в осмысленную информацию.Пакетная обработка - записи собираются, а затем обрабатываются вместе. В определенный интервал, определенный размер данных, в результате другого события.Потоковая обработка - источник отслеживается и данные обрабатывается в режиме реального времени по мере появления новых событий, связанных с данными.2\ Analytical data store:2а\ data warehouse - данные из транзакционных систем копируются в реляционную базу, где их удобно анализировать с помощью SQL. Данные хранятся в схеме.2б\ data lake - файловое хранилище для данных разных форматов (текст, изображения, видео, структур.и неструктур.данные), которые загружаются пакетами или стримингом, и обрабатываются с помощью распределённых систем (пр: Apache Spark, Hadoop). Cхема для файлов задаётся только при чтении2в\ Data lakehouse - сырые файлы хранятся в озере данных, а для анализа к ним можно обращаться как к таблицам через SQL-запросы. Поддерживает транзакции и разные способы загрузки данных.3\ Analytical data model - объединяет и организует данные для удобного анализа и создания отчётов и визуализаций (схемы «звезда», «снежинка», кубы).Куб — информация организована по нескольким измерениям (пря: время, продукт, регион).4\ Визуализация данных – аналитики данных используют данные из аналитических моделей и непосредственно из аналитических хранилищ для создания отчетов, панелей мониторинга и других визуализаций.**Другие сервисы Azure:**Microsoft Azure — это облачная платформа с множеством сервисов в т.ч. для OLTP&OLAP.1\ Microsoft Fabric (SaaS) - объединяет в одном мсте сервисы для интеграции данных (Data Factory), обработки и аналитики (Synapse), визуализации (Power BI) и автоматизации (Data Activator).OneLake — это единое, централизованное хранилище (аналитических данных) для Fabric (Azure, Amazon...)2\ Azure Data Factory - для определения и планирования конвейеров данных.Конвейер — автоматическая последовательность ETL-шагов.3\ Azure Databricks — это платформа для анализа больших объемов данных на Apache Spark с использованием интерактивных блокнотов.Apache Spark — это распределенная платформа обработки данных для анализа больших объемов информации. Spark можно использовать для параллельного выполнения кода (обычно написанного на Python, Scala или Java) на нескольких узлах кластера, что позволяет эффективно обрабатывать очень большие объемы данных. Spark можно использовать как для пакетной, так и для потоковой обработки.Delta Lake — слой хранения данных с открытым исходным кодом, который добавляет поддержку транзакций и проверку схемы. Delta Lake вместе со Spark позволяет удобно хранить и обрабатывать как потоковые, так и пакетные данные в виде таблиц, к которым можно делать SQL-запросы для анализа.4\ Azure Data Explorer - для телеметрии Интернета вещей (IoT).5\ Microsoft Purview - управления данными и их поиск в масштабах предприятия.**Архитектура потоковой обработки данных:**1\ Событие генерирует некоторые данные.2\ Сгенерированные данные захватываются в потоковом источнике (директория, таблица, очередь) для обработки.3\ Данные событий обрабатываются4\Результаты обработки потока записываются в хранилище, БД или на дашборд. 	Службы аналитики в реальном времени:1\ Azure Stream Analytics (PaaS) - обработки потоковых данных в реальном времени.2\ Spark Structured Streaming - библиотека предоставляет API для приема, обработки и вывода результатов из непрерывных потоков данных.В Spark для потоковой обработки используется структура «датафрейм», которая пополняется новыми данными из потока (пр: из хаба Kafka, файлов, сетевого порта). С помощью запросов к датафрейму можно выбирать и объединять данные, а результаты сохранять для анализа.3\ Microsoft Fabric Real-Time Intelligence - извлечение и и визуализация данных в движении. 	Источники для потоковой обработки:1\ Azure Event Hubs: служба приема данных для управления очередями событий.2\ Azure IoT Hub: служба приема данных, оптимизированная для IoT.3\ Azure Data Lake Store Gen 2: масштабируемая служба хранения, может использоваться в качестве источника потоковых данных.4\ Apache Kafka: решение для приема данных используемое вместе с Apache Spark. 	Приемники для потоковой обработки:1\ Azure Event Hubs: для постановки обработанных данных в очередь для дальнейшей обработки.2\ Azure Data Lake Store Gen 2, Microsoft OneLake или Azure blob storage: используются для сохранения обработанных результатов в файл.3\ Azure SQL Database, Azure Databricks или Microsoft Fabric: для сохранения результатов.4\ Microsoft Power BI: для создания визуализаций данных в режиме реального времени. **Power BI** Моделирование и визуализация данных позволяют организациям извлекать ценную информацию из данных.Microsoft Power BI — для создания интерактивных визуализаций данных для бизнес-юзеров.Power BI Desktop - позволяет импортировать данные из разных источников, объединять их в аналитической модели данных, а также создавать отчеты с интерактивными визуализациями.Показатели (меры) - числовые значения для анализа.Измерения - сущности, по которым агрегируют показатели.